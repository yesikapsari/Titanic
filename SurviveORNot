<h1> Assalamualaikum Wr. Wb. Hello everybody! I hope everythings good enough for you to create simple smile.
    This is my second project from me and the title is Titanic<h1>
    <h2> I get data from this https://www.kaggle.com/c/titanic/overview But somehow, I wanna to improve it with other source of data, so I hope it will finish as soon as possible <h2>
    import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV

#data reading
dftrain = pd.read_csv('titanic.csv')
dftrain.head(20)

#dicitionary
- survived ; 0 = no, 1 = yes
- pclass ; 1 = 1st, 2 = 2nd, 3 = 3rd
- sex ; sex
- age ; age in years
- sibsp ; # of siblings / spouses aboard the Titanic
- parch ; # of parents / children aboard the Titanic
- ticket ; ticket number
- fare ; passenger fare
- cabin ; cabin number
- emabarked ; port of embarkation ; C = Cherbourg, Q = Queenstown, S = Southampton

# exploratory data analysis (EDA)
dftrain.describe()
dftrain.shape
dftrain.info()

# data visualization
%matplotlib inline
sns.set()
# bar chart function
def piechart(a):
    survived = dftrain[dftrain['Survived']==1][a].value_counts()
    dead = dftrain[dftrain['Survived']==0][a].value_counts()
    df = pd.DataFrame([survived, dead])
    df.index = ['Survived', 'Dead']
    df.plot(kind='pie', subplots=True, autopct='%1.3f%%', startangle=90, figsize=(30,100), )
    
piechart('Pclass')

piechart('Sex')

def barchart(a):
    survived = dftrain[dftrain['Survived']==1][a].value_counts()
    dead = dftrain[dftrain['Survived']==0][a].value_counts()
    df = pd.DataFrame([survived, dead])
    df.index = ['Survived', 'Dead']
    df.plot(kind='bar', stacked=False, figsize=(12,8), )
    
barchart('SibSp')

barchart('Parch')

piechart('Embarked')

# feature engineering (encoding)
# import test data
dftest = pd.read_csv('titanic_test.csv')
dftest.head()

# name
combinedata = [dftrain, dftest]
for dataset in combinedata:
    dataset['Title'] = dataset['Name'].str.extract('([A-Za-z]+)\.', expand=False)
    
dftrain['Title'].value_counts()
dftest['Title'].value_counts()

titlemap = {'Mr':0, 'Miss':1, 'Mrs':2, 'Master':3, 'Dr':3, 'Rev':3,
            'Major':3, 'Col':3, 'Mlle':3, 'Jonkheer':3, 'Sir':3,
            'Lady':3, 'Don':3, 'Capt':3, 'Ms':3, 'Mme':3, 'Countess':3}
for dataset in combinedata:
    dataset['Title'] = dataset['Title'].map(titlemap)
    
 dftrain.head()
 
 piechart('Title')
 
 dftrain.drop('Name', axis=1, inplace=True)
dftest.drop('Name', axis=1, inplace=True)
#filling
for dataset in combinedata:
    dataset['Title'] = dataset['Title'].fillna(1)
    
#sex

sexmap = {'male': 0, 'female': 1}
for dataset in combinedata:
    dataset['Sex'] = dataset['Sex'].map(sexmap)
    
#age
#data cleasing/filling

dftrain['Age'].fillna(dftrain.groupby('Title')['Age'].transform('median')
                     , inplace=True)
dftest['Age'].fillna(dftest.groupby('Title')['Age'].transform('median')
                     , inplace=True)
                  
#binning

for dataset in combinedata:
    dataset.loc[dataset['Age'] <= 17, 'Age'] = 0
    dataset.loc[(dataset['Age'] > 17) & (dataset['Age'] <= 25), 'Age'] = 1
    dataset.loc[(dataset['Age'] > 25) & (dataset['Age'] <= 35), 'Age'] = 2
    dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 60), 'Age'] = 3
    dataset.loc[dataset['Age'] > 60, 'Age'] = 4
    
piechart('Age')

#embarked

PC1 = dftrain[dftrain['Pclass']==1]['Embarked'].value_counts()
PC2 = dftrain[dftrain['Pclass']==2]['Embarked'].value_counts()
PC3 = dftrain[dftrain['Pclass']==3]['Embarked'].value_counts()
PCall = pd.DataFrame([PC1, PC2, PC3])
PCall.index = ['1st class', '2nd class', '3rd class']
PCall.plot(kind='bar', stacked=True, figsize=(12,8))

#filling
for dataset in combinedata:
    dataset['Embarked'] = dataset['Embarked'].fillna('S')
embarkmap = {'S': 0, 'C': 1, 'Q': 2}
for dataset in combinedata:
    dataset['Embarked'] = dataset['Embarked'].map(embarkmap)
    
#fare
#filling
dftrain['Fare'].fillna(dftrain.groupby('Pclass')['Fare'].transform('median'), inplace=True)
dftest['Fare'].fillna(dftest.groupby('Pclass')['Fare'].transform('median'), inplace=True)

#visual check

FG = sns.FacetGrid(dftrain, hue='Survived', aspect=4)
FG.map(sns.kdeplot, 'Fare', shade=True)
FG.set(xlim=(0, dftrain['Fare'].max()))
FG.add_legend()
plt.show()

#binning

for dataset in combinedata:
    dataset.loc[dataset['Fare'] <= 18, 'Fare'] = 0
    dataset.loc[(dataset['Fare'] > 18) & (dataset['Fare'] <= 30), 'Fare'] = 1
    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2
    dataset.loc[dataset['Fare'] > 100, 'Fare'] = 3
    
dftrain['Fare'].value_counts()

piechart('Fare')

for dataset in combinedata:
    dataset['Cabin'] = dataset['Cabin'].str[:1]
 pc1 = dftrain[dftrain['Pclass']==1]['Cabin'].value_counts()
pc2 = dftrain[dftrain['Pclass']==2]['Cabin'].value_counts()
pc3 = dftrain[dftrain['Pclass']==3]['Cabin'].value_counts()
pcall = pd.DataFrame([pc1, pc2, pc3])
pcall.index = ['1st class', '2nd class', '3rd class']
pcall.plot(kind='bar', stacked=True, figsize=(12,8)) 

cabinmap = {'A':0, 'B':0.4, 'C':0.8, 'D':1.2, 'E':1.6, 'F':2,
            'G':2.4, 'T':2.8}
for dataset in combinedata:
    dataset['Cabin'] = dataset['Cabin'].map(cabinmap)
    
 #filling

dftrain['Cabin'].fillna(dftrain.groupby('Pclass')['Cabin'].transform('median'), inplace=True)
dftest['Cabin'].fillna(dftest.groupby('Pclass')['Cabin'].transform('median'), inplace=True)
   
#Family size

dftrain['famsize'] = dftrain['SibSp'] + dftrain['Parch'] + 1
dftest['famsize'] = dftest['SibSp'] + dftest['Parch'] + 1

fammap = {1:0, 2:0.4, 3:0.8, 4:1.2, 5:1.6, 6:2, 7:2.4, 8:2.8, 9:3.2, 10:3.6, 11:4}
for dataset in combinedata:
    dataset['Famsize'] = dataset['famsize'].map(fammap)
    
#data cleansing
feat_drop = ['SibSp', 'Parch', 'Ticket']
dftrain = dftrain.drop(feat_drop, axis=1)
dftest = dftest.drop(feat_drop, axis=1)
dftrain= dftrain.drop('PassengerId', axis=1)
predictor_data = dftrain.drop('Survived', axis=1)
target_data = dftrain['Survived']

# modelling
#cross validation
kfold = KFold(n_splits=10, shuffle=True, random_state=0)
#best param KNN
modelknn = KNeighborsClassifier(n_neighbors=20, weights='uniform')
param_grid ={'n_neighbors':np.arange(5,50), 'weights':['distance','uniform']}
gscv = GridSearchCV(modelknn, param_grid=param_grid, scoring='accuracy', cv=10)
gscv.fit(predictor_data, target_data)
gscv.best_params_

#KNN
modelknn = KNeighborsClassifier(n_neighbors=20, weights='uniform')
scoring = 'accuracy'
scoreknn = cross_val_score(modelknn, predictor_data, target_data, cv=kfold, n_jobs=1, scoring=scoring)
print(scoreknn)
#KNN score
np.mean(scoreknn)

#decision tree
modeldtc = DecisionTreeClassifier()
scoring = 'accuracy'
scoredtc = cross_val_score(modeldtc, predictor_data, target_data, cv=kfold, n_jobs=1, scoring=scoring)
print(scoredtc)
#decision tree score
np.mean(scoredtc)

# fit and test
modelknn = KNeighborsClassifier(n_neighbors=20, weights='uniform')
modelknn.fit(predictor_data, target_data)
datatest = dftest.drop('PassengerId', axis=1).copy()
predik = modelknn.predict(datatest)
result_data = pd.DataFrame({'PassengerId': dftest['PassengerId'],
                           'Survived': predik})
result_data.head(10)

# file saving
result_data.to_csv('submission.csv')
result_final = pd.read_csv('submission.csv')
result_final.head()
